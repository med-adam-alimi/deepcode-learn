DeepCodeLearn: AI-Powered Code Generation and Feedback Platform
üìå Overview
DeepCodeLearn is an innovative AI-powered platform designed to assist students and educators in computer science education. The platform leverages state-of-the-art Large Language Models (LLMs) to provide real-time code generation, evaluation, and personalized feedback for programming exercises. Developed as part of an internship project at the DES Research Unit in Sfax, Tunisia, this tool integrates modern web technologies with advanced AI techniques to enhance the learning experience.

‚ú® Key Features
AI-Powered Code Generation: Utilizes DeepSeek-Coder 1.3B LLM for accurate code solutions

Automated Evaluation: Combines test case validation and code similarity metrics

Intelligent Feedback: Provides contextual suggestions and error explanations

Multi-Language Support: Evaluates code in Python, Java, C++, and C

Educator Tools: Problem creation, student progress tracking, and analytics

Modern Web Architecture: Built with Next.js, FastAPI, and Firebase

üèÜ Core Achievements
Model Benchmarking: Comprehensive evaluation of LLMs (DeepSeek, CodeLlama, StarCoder)

Advanced Techniques: Implementation of RAG and prompt engineering for improved performance

Fair Evaluation System: Hybrid scoring combining test cases (60%) and code similarity (40%)

Production-Ready Platform: Scalable architecture with robust security measures

üõ†Ô∏è Technology Stack
Frontend
Next.js (React framework)

TypeScript

Tailwind CSS

Monaco Editor (VS Code-based code editor)

Backend
FastAPI (Python web framework)

Firebase (Authentication & Firestore)

HuggingFace Transformers (LLM integration)

AI/ML Components
DeepSeek-Coder 1.3B (Primary LLM)

PyTorch (Model execution)

RAG (Retrieval-Augmented Generation)

Prompt Engineering techniques

üìä Performance Highlights
Model	Size	Pass@1 Accuracy	Inference Speed
DeepSeek-Coder	1.3B	56.18%	Fast
CodeLlama	3B	52.00%	Moderate
StarCoder	3B	40.00%	Moderate
Achieved 95% accuracy on basic programming problems

Reduced inference time from 15s to 3s through optimization

Supports 100+ concurrent users with minimal latency

üöÄ Future Roadmap
Adaptive learning features based on student performance

Voice-driven feedback for accessibility

Multilingual support (French, Arabic, Spanish)

LMS integration (Moodle, GitHub Classroom)

Expansion to more programming languages

üìö Academic Contribution
This project represents significant research in:

LLM benchmarking for educational applications

Hybrid code evaluation methodologies

Practical implementation of RAG in education

Balancing model performance with real-world constraints

üôè Acknowledgments
Supervised by Dr. Mohamed Ali Haj Taieb at the DES Research Unit, Sfax
Developed by Mohamed Adam Alimi as part of the IT engineering program at the National Institute of Applied Science and Technology, Tunisia

üìÑ License
This project is intended for academic and research purposes. For usage rights, please contact the authors.

For more details, explore the full internship report included in this repository! Contributions and feedback are welcome.
